{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### WaveNet\n",
        "\n",
        "We will implement the [WaveNet](https://arxiv.org/pdf/1609.03499.pdf) Paper introduced by Deepmind as an early generative model, pre-transformer era.\n",
        "\n",
        "WaveNet is an autoregressive generative neural network, that is: it models conditional distributions based on sequences being passed in the model.\n",
        "\n",
        "## Core Implementation details:\n",
        "- Dilated Causal Convolutions\n",
        "- Quantized softmax\n",
        "- Gated activation units\n",
        "- Residual and Skip connections\n",
        "\n",
        "## Objective:\n",
        "- Implement core components using torch\n",
        "- Train and Evaluate\n",
        "- Build such that logic can be extended to text generation.\n",
        "- Bonus: Make some music!!"
      ],
      "metadata": {
        "id": "UDW_eDyxKapA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The joint probability of a waveform $x$ is given by $$p(x) = \\prod_{t=1}^{T} p(x_t|x_1,...,x_{t-1})   $$\n",
        "\n",
        "Thus each sample $x_t$ is conditioned on the samples at previous timestamps"
      ],
      "metadata": {
        "id": "SD7hirgDMofJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important Notes from paper that will help me write this up\n",
        "\n",
        "- There are no pooling layers in the network, and the\n",
        "output of the model has the same time dimensionality as the input.\n",
        "-  The model outputs a categorical\n",
        "distribution over the next value xt with a softmax layer and it is optimized to maximize the loglikelihood of the data w.r.t. the parameters.\n",
        "\n"
      ],
      "metadata": {
        "id": "vk5G7mNJNMvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR9CoarjQQ9y",
        "outputId": "884b8483-9ffc-4e9e-f3af-ee5cc14a1ef9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Acquire training data\n",
        "# !wget -O file1.zip \"https://mirg.city.ac.uk/datasets/magnatagatune/mp3.zip.001\"\n",
        "# !wget -O file2.zip \"https://mirg.city.ac.uk/datasets/magnatagatune/mp3.zip.002\"\n",
        "# !wget -O file3.zip \"https://mirg.city.ac.uk/datasets/magnatagatune/mp3.zip.003\"\n",
        "# !wget \"https://mirg.city.ac.uk/datasets/magnatagatune/annotations_final.csv\"\n",
        "\n",
        "# !mkdir audio\n",
        "# !cat file1.zip file2.zip file3.zip > audio/mp3_all.zip\n",
        "# !unzip audio/mp3_all.zip\n",
        "# !mv \"annotations_final.csv\" \"audio/annotations_final.csv\""
      ],
      "metadata": {
        "id": "fmsvXxzCMn3l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows',200)"
      ],
      "metadata": {
        "id": "dnqAVAGIMIC0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('audio/annotations_final.csv',delimiter='\\t')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "7JxwsOThYk_3",
        "outputId": "75a12553-5fe3-45e6-cfbc-85977b4b1957"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-87733535a264>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'audio/annotations_final.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'audio/annotations_final.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['folder'] = df['mp3_path'].apply(lambda x: x.split('/')[0])"
      ],
      "metadata": {
        "id": "96bpCg1TZi3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title music tags\n",
        "\n",
        "mus_tags =  ['no voice',\n",
        " 'singer',\n",
        " 'duet',\n",
        " 'plucking',\n",
        " 'hard rock',\n",
        " 'world',\n",
        " 'bongos',\n",
        " 'harpsichord',\n",
        " 'female singing',\n",
        " 'clasical',\n",
        " 'sitar',\n",
        " 'chorus',\n",
        " 'female opera',\n",
        " 'male vocal',\n",
        " 'vocals',\n",
        " 'clarinet',\n",
        " 'heavy',\n",
        " 'silence',\n",
        " 'beats',\n",
        " 'men',\n",
        " 'woodwind',\n",
        " 'funky',\n",
        " 'no strings',\n",
        " 'chimes',\n",
        " 'foreign',\n",
        " 'no piano',\n",
        " 'horns',\n",
        " 'classical',\n",
        " 'female',\n",
        " 'no voices',\n",
        " 'soft rock',\n",
        " 'eerie',\n",
        " 'spacey',\n",
        " 'jazz',\n",
        " 'guitar',\n",
        " 'quiet',\n",
        " 'no beat',\n",
        " 'banjo',\n",
        " 'electric',\n",
        " 'solo',\n",
        " 'violins',\n",
        " 'folk',\n",
        " 'female voice',\n",
        " 'wind',\n",
        " 'happy',\n",
        " 'ambient',\n",
        " 'new age',\n",
        " 'synth',\n",
        " 'funk',\n",
        " 'no singing',\n",
        " 'middle eastern',\n",
        " 'trumpet',\n",
        " 'percussion',\n",
        " 'drum',\n",
        " 'airy',\n",
        " 'voice',\n",
        " 'repetitive',\n",
        " 'birds',\n",
        " 'space',\n",
        " 'strings',\n",
        " 'bass',\n",
        " 'harpsicord',\n",
        " 'medieval',\n",
        " 'male voice',\n",
        " 'girl',\n",
        " 'keyboard',\n",
        " 'acoustic',\n",
        " 'loud',\n",
        " 'classic',\n",
        " 'string',\n",
        " 'drums',\n",
        " 'electronic',\n",
        " 'not classical',\n",
        " 'chanting',\n",
        " 'no violin',\n",
        " 'not rock',\n",
        " 'no guitar',\n",
        " 'organ',\n",
        " 'no vocal',\n",
        " 'talking',\n",
        " 'choral',\n",
        " 'weird',\n",
        " 'opera',\n",
        " 'soprano',\n",
        " 'fast',\n",
        " 'acoustic guitar',\n",
        " 'electric guitar',\n",
        " 'male singer',\n",
        " 'man singing',\n",
        " 'classical guitar',\n",
        " 'country',\n",
        " 'violin',\n",
        " 'electro',\n",
        " 'reggae',\n",
        " 'tribal',\n",
        " 'dark',\n",
        " 'male opera',\n",
        " 'no vocals',\n",
        " 'irish',\n",
        " 'electronica',\n",
        " 'horn',\n",
        " 'operatic',\n",
        " 'arabic',\n",
        " 'lol',\n",
        " 'low',\n",
        " 'instrumental',\n",
        " 'trance',\n",
        " 'chant',\n",
        " 'strange',\n",
        " 'drone',\n",
        " 'synthesizer',\n",
        " 'heavy metal',\n",
        " 'modern',\n",
        " 'disco',\n",
        " 'bells',\n",
        " 'man',\n",
        " 'deep',\n",
        " 'fast beat',\n",
        " 'industrial',\n",
        " 'hard',\n",
        " 'harp',\n",
        " 'no flute',\n",
        " 'jungle',\n",
        " 'pop',\n",
        " 'lute',\n",
        " 'female vocal',\n",
        " 'oboe',\n",
        " 'mellow',\n",
        " 'orchestral',\n",
        " 'viola',\n",
        " 'light',\n",
        " 'echo',\n",
        " 'piano',\n",
        " 'celtic',\n",
        " 'male vocals',\n",
        " 'orchestra',\n",
        " 'eastern',\n",
        " 'old',\n",
        " 'flutes',\n",
        " 'punk',\n",
        " 'spanish',\n",
        " 'sad',\n",
        " 'sax',\n",
        " 'slow',\n",
        " 'male',\n",
        " 'blues',\n",
        " 'vocal',\n",
        " 'indian',\n",
        " 'no singer',\n",
        " 'scary',\n",
        " 'india',\n",
        " 'woman',\n",
        " 'woman singing',\n",
        " 'rock',\n",
        " 'dance',\n",
        " 'piano solo',\n",
        " 'guitars',\n",
        " 'no drums',\n",
        " 'jazzy',\n",
        " 'singing',\n",
        " 'cello',\n",
        " 'calm',\n",
        " 'female vocals',\n",
        " 'voices',\n",
        " 'different',\n",
        " 'techno',\n",
        " 'clapping',\n",
        " 'house',\n",
        " 'monks',\n",
        " 'flute',\n",
        " 'not opera',\n",
        " 'not english',\n",
        " 'oriental',\n",
        " 'beat',\n",
        " 'upbeat',\n",
        " 'soft',\n",
        " 'noise',\n",
        " 'choir',\n",
        " 'female singer',\n",
        " 'rap',\n",
        " 'metal',\n",
        " 'hip hop',\n",
        " 'quick',\n",
        " 'water',\n",
        " 'baroque',\n",
        " 'women',\n",
        " 'fiddle',\n",
        " 'english']"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_uwKrmi8Z8xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = os.listdir('audio')\n",
        "folders = [x for x in folders if len(x)==1]"
      ],
      "metadata": {
        "id": "EyoBNEYXa-g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Create a 4x4 grid of histograms\n",
        "fig, axs = plt.subplots(4, 4, figsize=(15, 15))\n",
        "\n",
        "# Flatten the axis array for easy iteration\n",
        "axs = axs.flatten()\n",
        "\n",
        "# Plot histograms for each Pandas Series\n",
        "for i, folder_name in enumerate(folders):\n",
        "    ax = axs[i]  # Select the current axis\n",
        "    data = df[df['folder']==f'{folder_name}'][mus_tags].sum(axis=0).sort_values(ascending=False)[:10]\n",
        "    ax.bar(data.index,data.values)  # Plot histogram for the current data\n",
        "    ax.set_title(f\"Data {folder_name}\")  # Set title for each subplot\n",
        "    ax.set_xlabel('Values')  # Set x-axis label\n",
        "    ax.set_ylabel('Frequency')  # Set y-axis label\n",
        "    ax.set_xticklabels(data.index,rotation=45)\n",
        "\n",
        "# Adjust layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ot33PekEbYRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mus_tags"
      ],
      "metadata": {
        "id": "lMCOxtYNwcg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tags = ['ambient', 'classical', 'dance', 'electric' ,'electro', 'electronic', 'house','guitar','industrial','piano','jazz', 'jungle', 'metal', 'modern', 'new age', 'techno', 'trance','drums']\n",
        "df['selected_tag'] = df[mus_tags].apply(lambda row: row[row == 1].index.tolist(), axis=1)\n",
        "filtered_df = df[df['selected_tag'].apply(lambda x: any(tag in train_tags for tag in x))]"
      ],
      "metadata": {
        "id": "FQgaMUoFYorG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iw0QatPSwMCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.shape[0]"
      ],
      "metadata": {
        "id": "P5QkBszLwTNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have picked what data to train/eval our model on, it is important to figure out what it means to evaluate generative data. We will separate our data such that we can store the input matrix X as a fixed sequence and then we store the next step as Y.\n",
        "\n",
        "Consider our problem where we try to predict $x_t$ from $x_1,...,x_{t-1}$.\n",
        "We have to partition the soundbite into N-millisec partitions. For eg: $x_1$ would be from 00:00 to 00:0N.\n",
        "\n",
        "In the paper, for TTS, the receptive field was 240 ms. For generation, they do mention that the receptive field varies, we will experiment with this and see whats up."
      ],
      "metadata": {
        "id": "yGSzeurjxT2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Im assuming causal convolution for sound waves come in 1d since the order is inherently preserved.\n",
        "\n",
        "1 sec = 1000 ms = 25888   \n",
        "500 ms = 12944  \n",
        "250 ms = 6472  \n"
      ],
      "metadata": {
        "id": "429n9YeD1Qp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio"
      ],
      "metadata": {
        "id": "6PKHSdbq1_2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/audio/6/curandero-curandero-05-corriendo_juntos-0-29.mp3'"
      ],
      "metadata": {
        "id": "xxCPKuam2B6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waveform, sample_rate = torchaudio.load(f1)"
      ],
      "metadata": {
        "id": "wRI5FuXlz70u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waveform"
      ],
      "metadata": {
        "id": "Pw44Mdzc2NsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waveform.shape"
      ],
      "metadata": {
        "id": "6GIFjdHk2ewD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "465984//18"
      ],
      "metadata": {
        "id": "LDVN4B-Z2gfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "-LqwdvH52iEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_waveform = torch.randn((1,15))"
      ],
      "metadata": {
        "id": "m5eIGw6tf5el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "t_waveform"
      ],
      "metadata": {
        "id": "d2XEXsXxf-Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Conv1d(1,1,5,dilation=2)(t_waveform)\n",
        "# x = nn.Conv1d(1,1,6472,dilation=2)(x)\n",
        "# x = nn.Conv1d(1,1,6472,dilation=4)(x)\n",
        "# x = nn.Conv1d(1,1,6472,dilation=8)(x)"
      ],
      "metadata": {
        "id": "H0vceZmSeez0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "LdpTnz6Vg_sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "SBSIBUnje09x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waveform.shape"
      ],
      "metadata": {
        "id": "mkufNAN3e5nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "465984-459513"
      ],
      "metadata": {
        "id": "vA_48Jt2fYrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example input data\n",
        "batch_size = 1\n",
        "channels = 3\n",
        "input_length = 10\n",
        "\n",
        "# Define a dilated convolutional layer\n",
        "dilated_conv = nn.Conv1d(in_channels=channels, out_channels=channels, kernel_size=3, dilation=3)\n",
        "\n",
        "# Create a random input tensor\n",
        "input_data = torch.randn(batch_size, channels, input_length)\n",
        "\n",
        "# Apply dilated convolution to the input\n",
        "output = dilated_conv(input_data)\n",
        "\n",
        "print(\"Input shape:\", input_data.shape)\n",
        "print(\"Output shape:\", output.shape)\n"
      ],
      "metadata": {
        "id": "aYXVBh0cfv_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "853fdfa1-404e-4e69-ccc6-d2f88984c3ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([1, 3, 10])\n",
            "Output shape: torch.Size([1, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data"
      ],
      "metadata": {
        "id": "2C1uqhyahX2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "7MFrYvprhaM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blocks to build\n",
        "- Causal Conv Block\n",
        "- Dilated Conv Block\n",
        "- ResidualDilated Conv Block\n",
        "- TBC"
      ],
      "metadata": {
        "id": "M7gMt3gTQiu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Causal Conv Block\n",
        "\n",
        "- Consider an input sample of length N. Construct input matrix $V \\in \\mathbb{R}^{N\\times2}$ where the first column is all elements of V. The second column is all elements of V shifted by 1 (dilation)\n",
        "\n",
        "- Construct weight matrix $W$. Constructing only 1 layer blocks, the weight matrix will be of dimension $ N \\times 2$. Weights can be sampled from $N(0,1)$\n",
        "\n",
        "- Consider a stride of 1. Update mask after stride. Apply mask. Elem-wise mult between input vec and weight vec.\n",
        "\n",
        "- Padding."
      ],
      "metadata": {
        "id": "jnoPaHscRY_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1: How much padding?\n",
        "# Consider filter length K and stride 1.\n",
        "# Starting from element at position 1, there must be K-1 zeros before.\n",
        "# When we start the convolution, the only non-zero element would be at the end of the filter, and thats the first float in our original tensor. So we start convolution from there.\n",
        "\n",
        "# Question 2: Does passing affect anything about the matrix construction here?\n",
        "# Not really"
      ],
      "metadata": {
        "id": "LP6jss35hguc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 100\n",
        "N = 1024\n",
        "stride = 1\n",
        "signal = torch.randn((1,N))\n",
        "signal = torch.cat((torch.zeros((1,K-1)),signal),dim=1)\n",
        "signal = signal.view(-1).unsqueeze(1)\n",
        "signal_dilation_1 = torch.cat((signal[1:],torch.zeros(1,1)))\n",
        "V = torch.cat((signal,signal_dilation_1),dim=1)\n",
        "W = torch.randn((V.shape[0],2))"
      ],
      "metadata": {
        "id": "hUm11Iy3Q1VF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_window_idx = 0\n",
        "end_window_idx = K\n",
        "padded_signal_length = len(signal.view(-1))\n",
        "output_v = torch.zeros(V.shape[0])\n",
        "while end_window_idx <= padded_signal_length:\n",
        "  V_window = V[start_window_idx:end_window_idx,:]\n",
        "  W_window = W[start_window_idx:end_window_idx,:]\n",
        "  VW_window = V_window * W_window\n",
        "  VW = VW_window.sum(dim=1,keepdim=True)\n",
        "  output_v[start_window_idx] = VW.sum()\n",
        "\n",
        "  start_window_idx += stride\n",
        "  end_window_idx += stride"
      ],
      "metadata": {
        "id": "DQBmvfNcuw3A"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GzAnLS-pJD41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CausalConv1d:\n",
        "  def __init__(self,in_channels,out_channels,kernel_size,dilation,*args,**kwargs):\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.dilation = dilation\n",
        "    self.pad = (self.kernel_size - 1) * self.dilation\n",
        "    self.conv1d = nn.Conv1d(self.in_channels,self.out_channels,kernel_size=self.kernel_size,padding=self.pad,dilation=self.dilation,bias=False)\n",
        "\n",
        "  def __call__(self,x):\n",
        "    # x should be in shape (batch_size,num_samples,timestamp)\n",
        "    return self.conv1d(x)[:,:,:-self.pad]"
      ],
      "metadata": {
        "id": "hFX6Lk2cAKXR"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalConvBlock:\n",
        "  def __init__(self,layers,in_channels,out_channels,kernel_size):\n",
        "    self.layers = layers\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.module_list = nn.ModuleList()\n",
        "\n",
        "    for i in range(layers):\n",
        "      self.module_list.append(CausalConv1d(in_channels,out_channels,kernel_size,dilation=1))\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.module_list(x)"
      ],
      "metadata": {
        "id": "tI29NrRtJE-g"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DilatedConvBlock:\n",
        "  def __init__(self,in_channels,out_channels,kernel_size,dilation):\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.dilatedconv1d=CausalConv1d(in_channels,out_channels,kernel_size,dilation=dilation)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.dilatedconv1d(x)"
      ],
      "metadata": {
        "id": "mE_VKbU0rP5u"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvGate:\n",
        "  def apply(x):\n",
        "    tanh_x = torch.tanh(x)\n",
        "    sigmoid_x = torch.sigmoid(x)\n",
        "    return tanh_x * sigmoid_x"
      ],
      "metadata": {
        "id": "rGiTUmcQ0g2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DilatedResidualLayer:\n",
        "  def __init__(self,in_channels,skip_channels,kernel_size,dilation):\n",
        "    self.dilated_conv_block = DilatedConvBlock(in_channels,in_channels,kernel_size,dilation)\n",
        "    self.pointwise_conv_residual = nn.Conv1d(in_channels,in_channels,kernel_size=1,bias=True)\n",
        "    self.pointwise_conv_skip = nn.Conv1d(in_channels,skip_channels,kernel_size=1,bias=True)\n",
        "\n",
        "  def forward(self,x):\n",
        "    dilated_convolved_input = self.dilated_conv_block(x)\n",
        "    gated_input = ConvGate.apply(x)\n",
        "    pre_skip = self.pointwise_conv_residual(gated_input)\n",
        "    residual_input = pre_skip + x\n",
        "    skip_result = self.pointwise_conv_skip(gated_input)\n",
        "    return x, skip_result"
      ],
      "metadata": {
        "id": "qe398HKl3kxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DilatedResidualBlock:\n",
        "  def __init__(self,in_channels,skip_channels,kernel_size):\n",
        "    self.in_channels = in_channels\n",
        "    self.skip_channels = skip_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.layers = [2**i for i in range(10)]\n",
        "\n",
        "  def forward(self,x):\n",
        "    skip_results = []\n",
        "    for dilation in self.layers:\n",
        "      dilated_residual_layer = DilatedResidualLayer(self.in_channels,self.skip_channels,self.kernel_size,dilation)\n",
        "      x, skip_result = dilated_residual_layer.forward(x)\n",
        "      skip_results.append(skip_result)\n",
        "    return torch.vstack(skip_results)"
      ],
      "metadata": {
        "id": "Nqc4-awV7uTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseBlock:\n",
        "  def __init__(self,in_channels,skip_channels,kernel_size):\n",
        "    self.in_channels = in_channels\n",
        "    self.skip_channels = skip_channels\n",
        "\n",
        "  def quantized_softmax(self,x,mu):\n",
        "      prob = torch.log(1 + (mu*torch.abs(x)))/torch.log(1+mu)\n",
        "      return torch.sign(x) * prob\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = nn.ReLU(x,dim=2)\n",
        "    x = nn.Conv1d(self.in_channels,self.skip_channels,kernel_size=1,bias=True)(x)\n",
        "    x = nn.ReLU(x,dim=2)\n",
        "    x = nn.Conv1d(self.in_channels,self.skip_channels,kernel_size=1,bias=True)(x)\n",
        "    output = self.quantized_softmax(x,mu=255)\n",
        "    return output"
      ],
      "metadata": {
        "id": "PFK9ups197H5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "                                              Residual Block\n",
        "                        -------------------------------------------------------------------\n",
        "                        |                         ------->tanh--------                    |\n",
        "                        |                         |                   |                   |\n",
        "x --> CausalConvBlock --|----> DilatedConvBlock---|                   |--->1x1conv------->Add\n",
        "                                                  |                   |       |\n",
        "                                                  ------->sigmoid-----        |\n",
        "                                                                             Add\n",
        "                                                                             |||\n",
        "                                                                             |||\n",
        "                                                                        torch.stack() -> Dense\n",
        "'''"
      ],
      "metadata": {
        "id": "l9WcgKYh1T8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now pass the input thru 1 residual block with fixed dilation. The authors of the paper mention that dilation should be applied as follows `[1,2,4,8,...,512,1,2,...512,...]`.\n",
        "Thus one resnet block would have 9 layers. We would most probably have more than 1 block."
      ],
      "metadata": {
        "id": "XcNINTqozOcx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJWC6UnD7r42",
        "outputId": "98e7e79e-5e48-4188-f682-fc89d7550b35"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 4, 8, 16, 32, 64, 128, 256, 512]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KXRxATeq7rLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YOSVjUVo7WwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "2 ** 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8hEgo-S3s7e",
        "outputId": "1f53275d-492d-4aac-963b-3397661b730e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tanh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_eUiNdr0z4W",
        "outputId": "0cb52b94-e974-4249-9aa8-34555880fd00"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torch._VariableFunctionsClass.tanh>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualDilatedConvBlock:"
      ],
      "metadata": {
        "id": "ox0cd7X8z94L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KRDgxX3dz6hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DilatedConvBlock(in_channels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "ZsQcntiawVRg",
        "outputId": "fd201d18-1b4c-4e51-8283-75e8215b93cf"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-70bf506fa72a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDilatedConvBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: DilatedConvBlock.__init__() got an unexpected keyword argument 'in_channels'"
          ]
        }
      ]
    }
  ]
}